{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación\n",
    "Llamamos a pySpark e importamos todo lo necesario para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[3] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[3]\")\n",
    "print(sc)\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "import pyspark.ml.feature as ft\n",
    "import pyspark.sql.types as typ\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, IndexToString, OneHotEncoder, VectorAssembler, ChiSqSelector, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.evaluation as ev\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pyspark.ml.classification as cl\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de esquema\n",
    "Debido a que nuestro esquema inicial era bastante complejo, hemos creado este para asi darles los valores genéricos de String e Int a nuestras variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    ('index', typ.IntegerType()),\n",
    "    ('action_type', typ.StringType()),\n",
    "    ('combined_shot_type', typ.StringType()),\n",
    "    ('loc_x', typ.IntegerType()),\n",
    "    ('loc_y', typ.IntegerType()),\n",
    "    ('minutes_remaining', typ.IntegerType()),\n",
    "    ('period', typ.IntegerType()),\n",
    "    ('playoffs', typ.IntegerType()),\n",
    "    ('season', typ.StringType()),\n",
    "    ('seconds_remaining', typ.IntegerType()),\n",
    "    ('shot_distance', typ.IntegerType()),\n",
    "    ('shot_made_flag', typ.StringType()),\n",
    "    ('shot_type', typ.StringType()),\n",
    "    ('shot_zone_area', typ.StringType()),\n",
    "    ('shot_zone_basic', typ.StringType()),\n",
    "    ('shot_zone_range', typ.StringType()),\n",
    "    ('game_date', typ.StringType()),\n",
    "    ('matchup', typ.StringType()),\n",
    "    ('opponent', typ.StringType()),\n",
    "    ('shot_id', typ.IntegerType()),\n",
    "    ('angulo', typ.StringType())\n",
    "]\n",
    "     \n",
    "schema = typ.StructType([\n",
    "    typ.StructField(e[0], e[1], False) for e in labels\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameLimpioOficial.csv')\n",
    "datosDF = sqlContext.createDataFrame(datos,schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación get_dummy\n",
    "Esta función lo que nos permite es, principalmente indexar los strings, para que el OneHotEncoder pueda funcionar.\n",
    "\n",
    "Así podemos convertir nuestro dataset original en un DataFrame compuesto por el vector features, que contiene todos los Strings indexados además de las variables numéricas, y la columna label, que contiene el valor que queremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df,categoricalCols,continuousCols,labelCol):\n",
    "    \n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "    from pyspark.sql.functions import col\n",
    "    \n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categoricalCols ]\n",
    "    \n",
    "    # default setting: dropLast=True\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + continuousCols, outputCol=\"features\")\n",
    "    \n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "    \n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "    \n",
    "    data = data.withColumn('label',col(labelCol))\n",
    "    \n",
    "    return data.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(1774,[0,56,68,80...|  NaN|\n",
      "|(1774,[0,56,68,80...|  0.0|\n",
      "|(1774,[0,56,68,80...|  1.0|\n",
      "|(1774,[0,56,68,80...|  0.0|\n",
      "|(1774,[11,58,68,8...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catcols = ['action_type','combined_shot_type','season','shot_type','shot_zone_area','shot_zone_basic','shot_zone_range','game_date','matchup','opponent','angulo']\n",
    "\n",
    "num_cols = ['index','loc_x','loc_y','minutes_remaining','period','playoffs','seconds_remaining','shot_distance','shot_id']\n",
    "labelCol = 'shot_made_flag'\n",
    "\n",
    "data = get_dummy(datosDF,catcols,num_cols,labelCol)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos nuestro dataframe por el indexador de variables categóricas.\n",
    "    Primero nuestro label: labelIndexer.\n",
    "    Segundo el vector features: featureIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|label|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(1774,[0,56,68,80...|  NaN|         2.0|\n",
      "|(1774,[0,56,68,80...|  0.0|         0.0|\n",
      "|(1774,[0,56,68,80...|  1.0|         1.0|\n",
      "|(1774,[0,56,68,80...|  0.0|         0.0|\n",
      "|(1774,[11,58,68,8...|  1.0|         1.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(data)\n",
    "labelIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|     indexedFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(1774,[0,56,68,80...|  NaN|(1774,[0,56,68,80...|\n",
      "|(1774,[0,56,68,80...|  0.0|(1774,[0,56,68,80...|\n",
      "|(1774,[0,56,68,80...|  1.0|(1774,[0,56,68,80...|\n",
      "|(1774,[0,56,68,80...|  0.0|(1774,[0,56,68,80...|\n",
      "|(1774,[11,58,68,8...|  1.0|(1774,[11,58,68,8...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =VectorIndexer(inputCol=\"features\", \\\n",
    "                              outputCol=\"indexedFeatures\", \\\n",
    "                              maxCategories=4).fit(data)\n",
    "featureIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que hacemos es separar nuestro dataframe en e:\n",
    "1. Creamos el dataframe de los nulos al que llamamos dataNulos y lo quitamos del original mediente el .subtract.\n",
    "2. Creamos el dataframe de entrenamiento con el 80% de los datos.\n",
    "3. Creamos el dataframe de test mediante el .subtract, obteniendo así el 20% restante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNulos = data.where(isnan(col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = data.subtract(dataNulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data.sample(0.8,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.subtract(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos nuestro clasificador y lo evaluamos\n",
    "\n",
    "Utilizamos los parámetros por degecto del cl.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el labelConverter, cuya función es desindexar lo ya indexado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, logistic,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+\n",
      "|            features|label|predictedLabel|\n",
      "+--------------------+-----+--------------+\n",
      "|(1774,[0,56,61,80...|  0.0|           0.0|\n",
      "|(1774,[0,56,61,80...|  0.0|           0.0|\n",
      "|(1774,[0,56,62,82...|  0.0|           0.0|\n",
      "|(1774,[0,56,62,84...|  0.0|           0.0|\n",
      "|(1774,[0,56,66,80...|  0.0|           0.0|\n",
      "+--------------------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacemos la predicción final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(dataNulos)\n",
    "# Select example rows to display.\n",
    "prediccion = predictions.select(\"predictedLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lo pasamos todo al formato que nos pide kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.toPandas().to_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosPrediccion = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = datosNulos.drop('index', 1)\n",
    "datosNulos = datosNulos.drop('action_type', 1)\n",
    "datosNulos = datosNulos.drop('combined_shot_type', 1)\n",
    "datosNulos = datosNulos.drop('loc_x', 1)\n",
    "datosNulos = datosNulos.drop('loc_y', 1)\n",
    "datosNulos = datosNulos.drop('minutes_remaining', 1)\n",
    "datosNulos = datosNulos.drop('period', 1)\n",
    "datosNulos = datosNulos.drop('playoffs', 1)\n",
    "datosNulos = datosNulos.drop('season', 1)\n",
    "datosNulos = datosNulos.drop('seconds_remaining', 1)\n",
    "datosNulos = datosNulos.drop('shot_distance', 1)\n",
    "datosNulos = datosNulos.drop('shot_made_flag', 1)\n",
    "datosNulos = datosNulos.drop('shot_type', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_area', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_basic', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_range', 1)\n",
    "datosNulos = datosNulos.drop('game_date', 1)\n",
    "datosNulos = datosNulos.drop('matchup', 1)\n",
    "datosNulos = datosNulos.drop('opponent', 1)\n",
    "datosNulos = datosNulos.drop('angulo', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"shot_id\":datosNulos.shot_id,\n",
    "        \"shot_made_flag\":datosPrediccion.predictedLabel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(submission)\n",
    "df.to_csv('submission.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataHT = dataSN.sample(0.1,200)\n",
    "trainHT = dataHT.sample(0.8,200)\n",
    "testHT = dataHT.subtract(trainHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pipeline.fit(trainHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tune.ParamGridBuilder().addGrid(logistic.maxIter, [2, 10, 50, 100]).addGrid(logistic.regParam, [0.0, 0.01, 0.05, 0.3 ]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=logistic, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = model2.transform(trainHT)\n",
    "data_train = data_train.drop('prediction')\n",
    "data_train = data_train.drop('rawPrediction')\n",
    "data_train = data_train.drop('probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = model2.transform(testHT)\n",
    "data_test = data_test.drop('prediction')\n",
    "data_test = data_test.drop('rawPrediction')\n",
    "data_test = data_test.drop('probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cvModel.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(results)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Param (MaxIter):',cvModel.bestModel._java_obj.getMaxIter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Param (regParam):',cvModel.bestModel._java_obj.getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(\n",
    "    maxIter = cvModel.bestModel._java_obj.getMaxIter(), \n",
    "    regParam = cvModel.bestModel._java_obj.getRegParam(), \n",
    "    labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineHT = Pipeline(stages=[labelIndexer, featureIndexer, logistic,labelConverter])\n",
    "modelHT = pipelineHT.fit(train)\n",
    "predictionsHT = modelHT.transform(test)\n",
    "predictionsHT.select(\"features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsHT)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsHT = modelHT.transform(dataNulos)\n",
    "prediccionHT = predictionsHT.select(\"predictedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionHT.toPandas().to_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosPrediccion = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = datosNulos.drop('index', 1)\n",
    "datosNulos = datosNulos.drop('action_type', 1)\n",
    "datosNulos = datosNulos.drop('combined_shot_type', 1)\n",
    "datosNulos = datosNulos.drop('loc_x', 1)\n",
    "datosNulos = datosNulos.drop('loc_y', 1)\n",
    "datosNulos = datosNulos.drop('minutes_remaining', 1)\n",
    "datosNulos = datosNulos.drop('period', 1)\n",
    "datosNulos = datosNulos.drop('playoffs', 1)\n",
    "datosNulos = datosNulos.drop('season', 1)\n",
    "datosNulos = datosNulos.drop('seconds_remaining', 1)\n",
    "datosNulos = datosNulos.drop('shot_distance', 1)\n",
    "datosNulos = datosNulos.drop('shot_made_flag', 1)\n",
    "datosNulos = datosNulos.drop('shot_type', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_area', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_basic', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_range', 1)\n",
    "datosNulos = datosNulos.drop('game_date', 1)\n",
    "datosNulos = datosNulos.drop('matchup', 1)\n",
    "datosNulos = datosNulos.drop('opponent', 1)\n",
    "datosNulos = datosNulos.drop('angulo', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"shot_id\":datosNulos.shot_id,\n",
    "        \"shot_made_flag\":datosPrediccion.predictedLabel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(submission)\n",
    "df.to_csv('submissionHT.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar Variables Continuas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['loc_x'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='loc_x_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('loc_x')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['loc_y'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='loc_y_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('loc_y')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['shot_distance'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='shot_distance_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('shot_distance')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['minutes_remaining'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='minutes_remaining_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('minutes_remaining')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['period'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='period_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('period')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['playoffs'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='playoffs_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('playoffs')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ft.VectorAssembler(inputCols=['seconds_remaining'],outputCol= 'output')\n",
    "normalizer = ft.StandardScaler(inputCol=vectorizer.getOutputCol(),outputCol='seconds_remaining_normalized',withMean=True,withStd=True)\n",
    "pipeline = Pipeline(stages=[vectorizer, normalizer]) \n",
    "datosDF = pipeline.fit(datosDF).transform(datosDF)\n",
    "datosDF = datosDF.drop('seconds_remaining')\n",
    "datosDF = datosDF.drop('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = ['action_type','combined_shot_type','season','shot_type','shot_zone_area','shot_zone_basic','shot_zone_range','game_date','matchup','opponent','angulo']\n",
    "\n",
    "num_cols = ['index','loc_x_normalized','loc_y_normalized','minutes_remaining_normalized','period_normalized','playoffs_normalized','seconds_remaining_normalized','shot_distance_normalized','shot_id']\n",
    "labelCol = 'shot_made_flag'\n",
    "\n",
    "data = get_dummy(datosDF,catcols,num_cols,labelCol)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(data)\n",
    "labelIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =VectorIndexer(inputCol=\"features\", \\\n",
    "                              outputCol=\"indexedFeatures\", \\\n",
    "                              maxCategories=4).fit(data)\n",
    "featureIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNulosNVC = data.where(isnan(col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = data.subtract(dataNulosNVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNVC=dataSN.sample(0.8,200)\n",
    "trainNVC.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNVC = dataSN.subtract(trainNVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(\n",
    "    maxIter = cvModel.bestModel._java_obj.getMaxIter(), \n",
    "    regParam = cvModel.bestModel._java_obj.getRegParam(), \n",
    "    labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipelineNVC = Pipeline(stages=[labelIndexer, featureIndexer, logistic,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model. This also runs the indexers.\n",
    "modelNVC = pipelineNVC.fit(trainNVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictionsNVC = modelNVC.transform(testNVC)\n",
    "# Select example rows to display.\n",
    "prediccionNVC = predictionsNVC.select(\"features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsNVC)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsNVC = modelNVC.transform(dataNulosNVC)\n",
    "prediccionNVC = predictionsNVC.select(\"predictedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionNVC.toPandas().to_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosPrediccion = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = datosNulos.drop('index', 1)\n",
    "datosNulos = datosNulos.drop('action_type', 1)\n",
    "datosNulos = datosNulos.drop('combined_shot_type', 1)\n",
    "datosNulos = datosNulos.drop('loc_x', 1)\n",
    "datosNulos = datosNulos.drop('loc_y', 1)\n",
    "datosNulos = datosNulos.drop('minutes_remaining', 1)\n",
    "datosNulos = datosNulos.drop('period', 1)\n",
    "datosNulos = datosNulos.drop('playoffs', 1)\n",
    "datosNulos = datosNulos.drop('season', 1)\n",
    "datosNulos = datosNulos.drop('seconds_remaining', 1)\n",
    "datosNulos = datosNulos.drop('shot_distance', 1)\n",
    "datosNulos = datosNulos.drop('shot_made_flag', 1)\n",
    "datosNulos = datosNulos.drop('shot_type', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_area', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_basic', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_range', 1)\n",
    "datosNulos = datosNulos.drop('game_date', 1)\n",
    "datosNulos = datosNulos.drop('matchup', 1)\n",
    "datosNulos = datosNulos.drop('opponent', 1)\n",
    "datosNulos = datosNulos.drop('angulo', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"shot_id\":datosNulos.shot_id,\n",
    "        \"shot_made_flag\":datosPrediccion.predictedLabel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(submission)\n",
    "df.to_csv('submissionNVC.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=10, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "model = pca.fit(data)\n",
    "dataPCA = model.transform(data)\n",
    "dataPCA.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(dataPCA)\n",
    "labelIndexer.transform(dataPCA).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =VectorIndexer(inputCol=\"pca_features\", \\\n",
    "                              outputCol=\"indexedFeatures\", \\\n",
    "                              maxCategories=4).fit(dataPCA)\n",
    "featureIndexer.transform(dataPCA).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNulosPCA = dataPCA.where(isnan(col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = dataPCA.subtract(dataNulosPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPCA=dataSN.sample(0.8,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPCA = dataSN.subtract(trainPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(\n",
    "    maxIter = cvModel.bestModel._java_obj.getMaxIter(), \n",
    "    regParam = cvModel.bestModel._java_obj.getRegParam(), \n",
    "    labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipelinePCA = Pipeline(stages=[labelIndexer, featureIndexer, logistic,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model. This also runs the indexers.\n",
    "modelPCA = pipelinePCA.fit(trainPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictionsPCA = modelPCA.transform(testPCA)\n",
    "# Select example rows to display.\n",
    "prediccionPCA = predictionsPCA.select(\"pca_features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsPCA)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsPCA = modelPCA.transform(dataNulosPCA)\n",
    "prediccionPCA = predictionsPCA.select(\"predictedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionPCA.toPandas().to_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosPrediccion = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = datosNulos.drop('index', 1)\n",
    "datosNulos = datosNulos.drop('action_type', 1)\n",
    "datosNulos = datosNulos.drop('combined_shot_type', 1)\n",
    "datosNulos = datosNulos.drop('loc_x', 1)\n",
    "datosNulos = datosNulos.drop('loc_y', 1)\n",
    "datosNulos = datosNulos.drop('minutes_remaining', 1)\n",
    "datosNulos = datosNulos.drop('period', 1)\n",
    "datosNulos = datosNulos.drop('playoffs', 1)\n",
    "datosNulos = datosNulos.drop('season', 1)\n",
    "datosNulos = datosNulos.drop('seconds_remaining', 1)\n",
    "datosNulos = datosNulos.drop('shot_distance', 1)\n",
    "datosNulos = datosNulos.drop('shot_made_flag', 1)\n",
    "datosNulos = datosNulos.drop('shot_type', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_area', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_basic', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_range', 1)\n",
    "datosNulos = datosNulos.drop('game_date', 1)\n",
    "datosNulos = datosNulos.drop('matchup', 1)\n",
    "datosNulos = datosNulos.drop('opponent', 1)\n",
    "datosNulos = datosNulos.drop('angulo', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"shot_id\":datosNulos.shot_id,\n",
    "        \"shot_made_flag\":datosPrediccion.predictedLabel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(submission)\n",
    "df.to_csv('submissionPCA.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(data)\n",
    "dataEC = labelIndexer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ChiSqSelector(numTopFeatures=10, featuresCol=\"features\",\n",
    "                             outputCol=\"selectedFeatures\", labelCol=\"indexedLabel\")\n",
    "\n",
    "model = selector.fit(dataEC)\n",
    "\n",
    "print(\"ChiSqSelector output with top %d features selected\" % selector.getNumTopFeatures())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ChiSqSelector output with top %d features selected\" % \n",
    "selector.getNumTopFeatures())\n",
    "dataEC = model.transform(dataEC)\n",
    "dataEC = dataEC.drop('indexedLabel')\n",
    "dataEC.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importantFeatures = model.selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importantFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(dataEC)\n",
    "labelIndexer.transform(dataEC).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =VectorIndexer(inputCol=\"selectedFeatures\", \\\n",
    "                              outputCol=\"indexedFeatures\", \\\n",
    "                              maxCategories=4).fit(dataEC)\n",
    "featureIndexer.transform(dataEC).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNulosEC = dataEC.where(isnan(col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSN = dataEC.subtract(dataNulosEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEC=dataSN.sample(0.8,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEC = dataSN.subtract(trainEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(\n",
    "    maxIter = cvModel.bestModel._java_obj.getMaxIter(), \n",
    "    regParam = cvModel.bestModel._java_obj.getRegParam(), \n",
    "    labelCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipelineEC = Pipeline(stages=[labelIndexer, featureIndexer, logistic,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model. This also runs the indexers.\n",
    "modelEC = pipelineEC.fit(trainEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictionsEC = modelEC.transform(testEC)\n",
    "# Select example rows to display.\n",
    "prediccionEC = predictionsEC.select(\"selectedFeatures\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsEC)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsEC = modelEC.transform(dataNulosEC)\n",
    "prediccionEC = predictionsEC.select(\"predictedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionEC.toPandas().to_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data I/Proyecto/Datos/DataFrameNulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosPrediccion = pd.read_csv('/Users/joxea/OneDrive/Documentos/UEM/Segundo Curso/Proyecto de Open Data II/prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosNulos = datosNulos.drop('index', 1)\n",
    "datosNulos = datosNulos.drop('action_type', 1)\n",
    "datosNulos = datosNulos.drop('combined_shot_type', 1)\n",
    "datosNulos = datosNulos.drop('loc_x', 1)\n",
    "datosNulos = datosNulos.drop('loc_y', 1)\n",
    "datosNulos = datosNulos.drop('minutes_remaining', 1)\n",
    "datosNulos = datosNulos.drop('period', 1)\n",
    "datosNulos = datosNulos.drop('playoffs', 1)\n",
    "datosNulos = datosNulos.drop('season', 1)\n",
    "datosNulos = datosNulos.drop('seconds_remaining', 1)\n",
    "datosNulos = datosNulos.drop('shot_distance', 1)\n",
    "datosNulos = datosNulos.drop('shot_made_flag', 1)\n",
    "datosNulos = datosNulos.drop('shot_type', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_area', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_basic', 1)\n",
    "datosNulos = datosNulos.drop('shot_zone_range', 1)\n",
    "datosNulos = datosNulos.drop('game_date', 1)\n",
    "datosNulos = datosNulos.drop('matchup', 1)\n",
    "datosNulos = datosNulos.drop('opponent', 1)\n",
    "datosNulos = datosNulos.drop('angulo', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"shot_id\":datosNulos.shot_id,\n",
    "        \"shot_made_flag\":datosPrediccion.predictedLabel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(submission)\n",
    "df.to_csv('submissionEC.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
